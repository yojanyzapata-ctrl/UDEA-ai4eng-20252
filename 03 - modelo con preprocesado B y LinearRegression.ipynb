{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###**Modelo con preprocesado B y LinearRegression**"
      ],
      "metadata": {
        "id": "7jlkhH3EsD2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Cargar librerías**"
      ],
      "metadata": {
        "id": "72Oz7myHsIMT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "hOtCmee0qV_U"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy import sparse\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Carga del conjunto de datos Train y Test**"
      ],
      "metadata": {
        "id": "0buB8JSZsMtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = \".\"  #Se establece la variable de entorno al directorio actual"
      ],
      "metadata": {
        "id": "PoxvVH2usd4b"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c udea-ai-4-eng-20252-pruebas-saber-pro-colombia  # Se descargan los archivos de la competencia directamente desde la API de Kaggle"
      ],
      "metadata": {
        "id": "O1-yWo2DskyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe540b0f-bd60-4b85-b446-6b5863c5ab6f"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 ./kaggle.json'\n",
            "udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip # Se descomprime el fichero para acceder al contenido"
      ],
      "metadata": {
        "id": "_MNOebxqsmGk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50bbab03-e74d-43ed-c9c1-bdb94acaad15"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip\n",
            "  inflating: submission_example.csv  \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar train y test\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "test  = pd.read_csv(\"test.csv\")"
      ],
      "metadata": {
        "id": "4Te1v-His6VU"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Limpieza de datos**"
      ],
      "metadata": {
        "id": "1WaaWMdHH1WJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####**Eliminación de las columnas innecesarias**"
      ],
      "metadata": {
        "id": "Mmh8QEEiIGBq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta versión del preprocesado eliminamos otras columnas del dataset que no aportan información útil para el modelo. Esto incluye columnas duplicadas y columnas redundantes con otras variables."
      ],
      "metadata": {
        "id": "4Tar7eknit7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del(train[\"ID\"])\n",
        "\n",
        "del(train[\"F_TIENEINTERNET.1\"]) # Columna duplicada\n",
        "del(test[\"F_TIENEINTERNET.1\"])\n",
        "\n",
        "del(train[\"F_TIENELAVADORA\"]) # Redundate con estrato socioeconómico\n",
        "del(test[\"F_TIENELAVADORA\"])\n",
        "\n",
        "del(train[\"F_TIENEAUTOMOVIL\"]) # Redundate con estrato socioeconómico\n",
        "del(test[\"F_TIENEAUTOMOVIL\"])\n",
        "\n",
        "del(train[\"E_PAGOMATRICULAPROPIO\"]) # Redundate con valor de matrícula\n",
        "del(test[\"E_PAGOMATRICULAPROPIO\"])\n",
        "\n",
        "del(train[\"PERIODO_ACADEMICO\"]) # No aporta información relevante\n",
        "del(test[\"PERIODO_ACADEMICO\"])\n",
        "\n",
        "del(train[\"E_PRIVADO_LIBERTAD\"]) # No aporta información relevante\n",
        "del(test[\"E_PRIVADO_LIBERTAD\"])"
      ],
      "metadata": {
        "id": "D9lVXEo2k4or"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Tratamiento de Datos Faltantes**\n"
      ],
      "metadata": {
        "id": "FMwxhwCsIMrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col_Nanh = train.isna().sum()\n",
        "col_Nanh[col_Nanh!=0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "UuQQfzIfRqgb",
        "outputId": "6ebf48e0-2ad1-4ea3-e7dd-b798525f5358"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "E_VALORMATRICULAUNIVERSIDAD     6287\n",
              "E_HORASSEMANATRABAJA           30857\n",
              "F_ESTRATOVIVIENDA              32137\n",
              "F_TIENEINTERNET                26629\n",
              "F_EDUCACIONPADRE               23178\n",
              "F_TIENECOMPUTADOR              38103\n",
              "F_EDUCACIONMADRE               23664\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>E_VALORMATRICULAUNIVERSIDAD</th>\n",
              "      <td>6287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>E_HORASSEMANATRABAJA</th>\n",
              "      <td>30857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F_ESTRATOVIVIENDA</th>\n",
              "      <td>32137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F_TIENEINTERNET</th>\n",
              "      <td>26629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F_EDUCACIONPADRE</th>\n",
              "      <td>23178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F_TIENECOMPUTADOR</th>\n",
              "      <td>38103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F_EDUCACIONMADRE</th>\n",
              "      <td>23664</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imputamos los valores faltantes de ciertas columnas categóricas usando la moda."
      ],
      "metadata": {
        "id": "mgFRVHeiTmaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Columnas a imputar con la moda\n",
        "cols_a_imputar = ['F_ESTRATOVIVIENDA', 'F_EDUCACIONPADRE', 'F_EDUCACIONMADRE',\n",
        "                  'F_TIENEINTERNET', 'F_TIENECOMPUTADOR']\n",
        "\n",
        "# Calcular la moda en TRAIN\n",
        "moda_train = train[cols_a_imputar].mode().iloc[0]\n",
        "\n",
        "# Imputación en TRAIN usando su propia moda\n",
        "train[cols_a_imputar] = train[cols_a_imputar].fillna(moda_train)\n",
        "\n",
        "# Imputación en TEST usando la moda del TRAIN para no usar los datos de test\n",
        "test[cols_a_imputar] = test[cols_a_imputar].fillna(moda_train)\n",
        "\n",
        "# Verificación\n",
        "print(\"Nulos en train:\\n\", train[cols_a_imputar].isnull().sum())\n",
        "print(\"Nulos en test:\\n\", test[cols_a_imputar].isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uS7Q0tkR_sT",
        "outputId": "f28a8c5e-c448-4082-db2f-9a44b75f9123"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nulos en train:\n",
            " F_ESTRATOVIVIENDA    0\n",
            "F_EDUCACIONPADRE     0\n",
            "F_EDUCACIONMADRE     0\n",
            "F_TIENEINTERNET      0\n",
            "F_TIENECOMPUTADOR    0\n",
            "dtype: int64\n",
            "Nulos en test:\n",
            " F_ESTRATOVIVIENDA    0\n",
            "F_EDUCACIONPADRE     0\n",
            "F_EDUCACIONMADRE     0\n",
            "F_TIENEINTERNET      0\n",
            "F_TIENECOMPUTADOR    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, se rellenan los valores faltantes por \"missing\" en los valores nulos faltantes."
      ],
      "metadata": {
        "id": "lFK8ci-tlnRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = train.fillna(\"missing\")\n",
        "df_test = test.fillna(\"missing\")"
      ],
      "metadata": {
        "id": "gZO8qsOSUpX5"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####**Codificación de Variables Categóricas con One Hot**"
      ],
      "metadata": {
        "id": "W-BFxxdoITcy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para esta versión solo ciertas columnas son transformadas mediante One Hot Encodin (programa académico y el departamento)."
      ],
      "metadata": {
        "id": "udMu69Q2mAxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import sparse as sp\n",
        "\n",
        "#Estas funciones permiten trasnformar las variables categóricas en formato One-Hot\n",
        "def to_onehot(x): # Convierte una variable categórica a formato One Hot\n",
        "    values = np.unique(x)\n",
        "    r = np.r_[[np.argwhere(i == values)[0][0] for i in x]]\n",
        "    onehot_sparse = sparse.csr_matrix(\n",
        "        (np.ones(len(r)), (np.arange(len(r)), r)),\n",
        "        shape=(len(r), len(values))\n",
        "    )\n",
        "    return onehot_sparse, values\n",
        "\n",
        "# Reemplaza una columna por su versión One Hot\n",
        "def replace_column_with_onehot(d, col):\n",
        "    assert sum(d[col].isna()) == 0, \"column must have no NaN values\"\n",
        "    k_sparse, values = to_onehot(d[col].values)\n",
        "    k = pd.DataFrame.sparse.from_spmatrix(\n",
        "        k_sparse,\n",
        "        columns=[\"%s_%s\" % (col, values[i]) for i in range(k_sparse.shape[1])],\n",
        "        index=d.index\n",
        "    )\n",
        "    r = k.join(d)\n",
        "    del (r[col])\n",
        "    return r\n",
        "\n",
        "# Aplica One-Hot Encoding a múltiples columnas categóricas\n",
        "def aplicar_onehot_a_varias(df, columnas):\n",
        "    df_datos = df.copy()\n",
        "    for col in columnas:\n",
        "        df_datos = replace_column_with_onehot(df_datos, col)\n",
        "    return df_datos\n"
      ],
      "metadata": {
        "id": "yfcmFZ-FtazJ"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Columnas para aplicar one-hot\n",
        "cols_onehot = [\n",
        "    \"E_PRGM_DEPARTAMENTO\",\n",
        "    \"E_PRGM_ACADEMICO\"\n",
        "]\n",
        "\n",
        "# Aplicamos la función a train y test\n",
        "df_train_onehot = aplicar_onehot_a_varias(df_train, cols_onehot)\n",
        "df_test_onehot = aplicar_onehot_a_varias(df_test, cols_onehot)\n",
        "\n",
        "# Verificamos shapes\n",
        "print(df_train_onehot.shape, df_test_onehot.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J19cop36yco3",
        "outputId": "889fccb5-c3f7-43a0-cf8c-66b1ac7a1bd9"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(692500, 991) (296786, 962)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Tratamiento de Variables Categóricas Ordinales**"
      ],
      "metadata": {
        "id": "tBs1ont6Is3c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para el tratamiento de variables categóricas ordinales se decide variar levemente el mapeo, por ejemplo en el caso del rendimiento global, que ahora inicia desde 1 en lugar de 0."
      ],
      "metadata": {
        "id": "67WPy_CzmZhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def codificar_ordinal(df, mapeos):\n",
        "    df_copia = df.copy()\n",
        "    for col, mapa in mapeos.items():\n",
        "        if col in df_copia.columns:\n",
        "            df_copia[col] = df_copia[col].map(mapa)\n",
        "    return df_copia\n",
        "\n",
        "mapeos_train = {\n",
        "    'E_VALORMATRICULAUNIVERSIDAD': {\n",
        "        'missing': -1,\n",
        "        'No pagó matrícula': 0,\n",
        "        'Menos de 500 mil': 0.25,\n",
        "        'Entre 500 mil y menos de 1 millón': 0.75,\n",
        "        'Entre 1 millón y menos de 2.5 millones': 1.75,\n",
        "        'Entre 2.5 millones y menos de 4 millones': 3.25,\n",
        "        'Entre 4 millones y menos de 5.5 millones': 4.25,\n",
        "        'Entre 5.5 millones y menos de 7 millones': 6.25,\n",
        "        'Más de 7 millones': 8\n",
        "    },\n",
        "    'E_HORASSEMANATRABAJA': {\n",
        "        'missing': -1,\n",
        "        '0': 0,\n",
        "        'Menos de 10 horas': 5,\n",
        "        'Entre 11 y 20 horas': 15,\n",
        "        'Entre 21 y 30 horas': 25,\n",
        "        'Más de 30 horas': 35\n",
        "    },\n",
        "    'F_ESTRATOVIVIENDA': {\n",
        "        'Sin Estrato': 0,\n",
        "        'Estrato 1': 1,\n",
        "        'Estrato 2': 2,\n",
        "        'Estrato 3': 3,\n",
        "        'Estrato 4': 4,\n",
        "        'Estrato 5': 5,\n",
        "        'Estrato 6': 6\n",
        "    },\n",
        "    'F_EDUCACIONPADRE': {\n",
        "        'No sabe': -1,\n",
        "        'No Aplica': 0,\n",
        "        'Ninguno': 1,\n",
        "        'Primaria incompleta': 2,\n",
        "        'Primaria completa': 3,\n",
        "        'Secundaria (Bachillerato) incompleta': 4,\n",
        "        'Secundaria (Bachillerato) completa': 5,\n",
        "        'Técnica o tecnológica incompleta': 6,\n",
        "        'Técnica o tecnológica completa': 7,\n",
        "        'Educación profesional incompleta': 8,\n",
        "        'Educación profesional completa': 9,\n",
        "        'Postgrado': 10\n",
        "    },\n",
        "    'F_EDUCACIONMADRE': {\n",
        "        'No sabe': -1,\n",
        "        'No Aplica': 0,\n",
        "        'Ninguno': 1,\n",
        "        'Primaria incompleta': 2,\n",
        "        'Primaria completa': 3,\n",
        "        'Secundaria (Bachillerato) incompleta': 4,\n",
        "        'Secundaria (Bachillerato) completa': 5,\n",
        "        'Técnica o tecnológica incompleta': 6,\n",
        "        'Técnica o tecnológica completa': 7,\n",
        "        'Educación profesional incompleta': 8,\n",
        "        'Educación profesional completa': 9,\n",
        "        'Postgrado': 10\n",
        "    },\n",
        "    \"F_TIENEINTERNET\": {\n",
        "        \"No\": 0,\n",
        "        \"Si\": 1\n",
        "    },\n",
        "    \"F_TIENECOMPUTADOR\": {\n",
        "        \"No\": 0,\n",
        "        \"Si\": 1\n",
        "    },\n",
        "    'RENDIMIENTO_GLOBAL': {  # Intentamos con mapeo diferente\n",
        "        'bajo': 1,\n",
        "        'medio-bajo': 2,\n",
        "        'medio-alto': 3,\n",
        "        'alto': 4\n",
        "    }\n",
        "}\n",
        "\n",
        "mapeos_test = {\n",
        "    'E_VALORMATRICULAUNIVERSIDAD': {\n",
        "        'missing': -1,\n",
        "        'No pagó matrícula': 0,\n",
        "        'Menos de 500 mil': 0.25,\n",
        "        'Entre 500 mil y menos de 1 millón': 0.75,\n",
        "        'Entre 1 millón y menos de 2.5 millones': 1.75,\n",
        "        'Entre 2.5 millones y menos de 4 millones': 3.25,\n",
        "        'Entre 4 millones y menos de 5.5 millones': 4.25,\n",
        "        'Entre 5.5 millones y menos de 7 millones': 6.25,\n",
        "        'Más de 7 millones': 8\n",
        "    },\n",
        "    'E_HORASSEMANATRABAJA': {\n",
        "        'missing': -1,\n",
        "        '0': 0,\n",
        "        'Menos de 10 horas': 5,\n",
        "        'Entre 11 y 20 horas': 15,\n",
        "        'Entre 21 y 30 horas': 25,\n",
        "        'Más de 30 horas': 35\n",
        "    },\n",
        "    'F_ESTRATOVIVIENDA': {\n",
        "        'Sin Estrato': 0,\n",
        "        'Estrato 1': 1,\n",
        "        'Estrato 2': 2,\n",
        "        'Estrato 3': 3,\n",
        "        'Estrato 4': 4,\n",
        "        'Estrato 5': 5,\n",
        "        'Estrato 6': 6\n",
        "    },\n",
        "    'F_EDUCACIONPADRE': {\n",
        "        'No sabe': -1,\n",
        "        'No Aplica': 0,\n",
        "        'Ninguno': 1,\n",
        "        'Primaria incompleta': 2,\n",
        "        'Primaria completa': 3,\n",
        "        'Secundaria (Bachillerato) incompleta': 4,\n",
        "        'Secundaria (Bachillerato) completa': 5,\n",
        "        'Técnica o tecnológica incompleta': 6,\n",
        "        'Técnica o tecnológica completa': 7,\n",
        "        'Educación profesional incompleta': 8,\n",
        "        'Educación profesional completa': 9,\n",
        "        'Postgrado': 10\n",
        "    },\n",
        "    'F_EDUCACIONMADRE': {\n",
        "        'No sabe': -1,\n",
        "        'No Aplica': 0,\n",
        "        'Ninguno': 1,\n",
        "        'Primaria incompleta': 2,\n",
        "        'Primaria completa': 3,\n",
        "        'Secundaria (Bachillerato) incompleta': 4,\n",
        "        'Secundaria (Bachillerato) completa': 5,\n",
        "        'Técnica o tecnológica incompleta': 6,\n",
        "        'Técnica o tecnológica completa': 7,\n",
        "        'Educación profesional incompleta': 8,\n",
        "        'Educación profesional completa': 9,\n",
        "        'Postgrado': 10\n",
        "    },\n",
        "    \"F_TIENEINTERNET\": {\n",
        "        \"No\": 0,\n",
        "        \"Si\": 1\n",
        "    },\n",
        "    \"F_TIENECOMPUTADOR\": {\n",
        "        \"No\": 0,\n",
        "        \"Si\": 1\n",
        "    }\n",
        "}\n",
        "\n",
        "df_train_ord = codificar_ordinal(df_train_onehot, mapeos_train)\n",
        "df_test_ord  = codificar_ordinal(df_test_onehot, mapeos_test)"
      ],
      "metadata": {
        "id": "gWdMfA4lzvh5"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Normalización de Columnas**"
      ],
      "metadata": {
        "id": "pSTcskJwN7al"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta versión se deciden normalizar todas las variables numéricas para asegurar que estén en la misma escala."
      ],
      "metadata": {
        "id": "C5Dd_bMFnstD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "escalar = StandardScaler()\n",
        "# Columnas que realmente son numéricas y deben normalizarse\n",
        "columnas_a_normalizar = [\n",
        "    \"E_VALORMATRICULAUNIVERSIDAD\",\n",
        "    \"E_HORASSEMANATRABAJA\",\n",
        "    \"INDICADOR_1\",\n",
        "    \"INDICADOR_2\",\n",
        "    \"INDICADOR_3\",\n",
        "    \"INDICADOR_4\"\n",
        "]\n",
        "\n",
        "\n",
        "escalar = StandardScaler()\n",
        "# Ajustar el escalador a los datos y transformar las columnas\n",
        "df_train_ord[columnas_a_normalizar] = escalar.fit_transform(df_train_ord[columnas_a_normalizar])\n",
        "df_test_ord[columnas_a_normalizar]  = escalar.transform(df_test_ord[columnas_a_normalizar])\n",
        "\n",
        "df_train_final = df_train_ord.copy()\n",
        "df_test_final = df_test_ord.copy()"
      ],
      "metadata": {
        "id": "UsjFz6cVCUCr"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Modelo LinearRegression**"
      ],
      "metadata": {
        "id": "NCBt9y3RN-qi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se aplica un modelo de regresión lineal y se evalúa su desempeño utilizando una partición de los datos de train en 70% para entrenamiento y 30% para prueba."
      ],
      "metadata": {
        "id": "O2VfWFgTn8f_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable objetivo\n",
        "y = df_train_final[\"RENDIMIENTO_GLOBAL\"]\n",
        "\n",
        "# Variables predictoras\n",
        "X = df_train_final.drop(columns=[\"RENDIMIENTO_GLOBAL\"])\n",
        "\n",
        "# Separar train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7)\n",
        "\n",
        "# Ajustar modelo\n",
        "estimator = LinearRegression()\n",
        "estimator.fit(X_train, y_train)\n",
        "\n",
        "# Predicciones\n",
        "y_pred = estimator.predict(X_test)\n",
        "\n",
        "# Convertir a clases discretas\n",
        "y_pred_clases = np.clip(np.round(y_pred), 0, 3).astype(int)\n",
        "\n",
        "# Calcular accuracy\n",
        "acc = accuracy_score(y_test, y_pred_clases)\n",
        "print(\"Accuracy aproximado:\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ah30ynDb4wB",
        "outputId": "2d8974e3-5cf8-40ae-b94d-c151f8ac9dee"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy aproximado: 0.3016317689530686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Técnicas de Validación**"
      ],
      "metadata": {
        "id": "EqsF2vKnoN2U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se aplica un modelo de regresión lineal y se evalúa su desempeño usando como métrica el error absoluto medio relativo (MAE)."
      ],
      "metadata": {
        "id": "ws0MO9x-ojC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construimos nuestra medida de desempeño\n",
        "def rel_mae_mean(estimator, X, y):\n",
        "    preds = estimator.predict(X)\n",
        "    mae = np.mean(np.abs(preds - y))\n",
        "    return mae / np.mean(y)\n",
        "\n",
        "def bootstrap_score(estimator, X, y, test_size):\n",
        "    trscores, tsscores = [], []\n",
        "    for _ in range(2):\n",
        "        Xtr, Xts, ytr, yts = train_test_split(X, y, test_size=test_size)\n",
        "        estimator.fit(Xtr, ytr)\n",
        "        trscores.append(rel_mae_mean(estimator, Xtr, ytr))\n",
        "        tsscores.append(rel_mae_mean(estimator, Xts, yts))\n",
        "    return (np.mean(trscores), np.std(trscores)), (np.mean(tsscores), np.std(tsscores))\n",
        "\n",
        "estimator_bt = LinearRegression()\n",
        "(trmean, trstd), (tsmean, tsstd) = bootstrap_score(estimator_bt, X, y, test_size=0.3)\n",
        "\n",
        "print(\"train score %.3f (±%.4f)\" % (trmean, trstd))\n",
        "print(\"test score  %.3f (±%.4f)\" % (tsmean, tsstd))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHTPmxU6OI74",
        "outputId": "294dbd85-f34d-40fb-b8ba-7b44b817222f"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train score 0.325 (±0.0001)\n",
            "test score  0.326 (±0.0003)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Validación Cruzada**"
      ],
      "metadata": {
        "id": "yGS53edJqD1i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####**Uso de ShuffleSplit**"
      ],
      "metadata": {
        "id": "MrxkHB8cbndY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se utilizó validación cruzada con ShuffleSplit. Se realizaron tres particiones del dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "0JTDHol1pyhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo\n",
        "estimator_sh = LinearRegression()\n",
        "\n",
        "# ShuffleSplit CV\n",
        "cv = ShuffleSplit(n_splits=3, test_size=0.3, random_state=7)\n",
        "\n",
        "# Evaluación con tu métrica personalizada\n",
        "z = cross_val_score(estimator_sh, X, y, cv=cv, scoring=rel_mae_mean)\n",
        "print(z)\n",
        "print(\"test score %.3f (±%.4f)\" % (np.mean(z), np.std(z)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Do_Rdmff-I1",
        "outputId": "1e9abe2e-59be-48ea-c666-e6bdac06e7e5"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.32534853 0.32682879 0.32606809]\n",
            "test score 0.326 (±0.0006)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Generación del CSV - Kaggle**"
      ],
      "metadata": {
        "id": "TwX57x05qPKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Alinear columnas de test con las de train\n",
        "# Se eliminan atributos adicionales presentes solo en test (programas académicos sobre los cuales train no tiene información)\n",
        "X_test_aligned = df_test_final.reindex(columns=X.columns, fill_value=0)\n",
        "\n",
        "# Generar predicciones con el modelo entrenado\n",
        "y_pred = estimator.predict(X_test_aligned)\n",
        "\n",
        "# Convertir predicciones continuas a clases discretas\n",
        "y_pred_clases = np.clip(np.round(y_pred), 0, 3).astype(int)\n",
        "\n",
        "# Mapear números a originales\n",
        "num_to_label = {0:'bajo', 1:'medio-bajo', 2:'medio-alto', 3:'alto'}\n",
        "y_pred_labels = [num_to_label[i] for i in y_pred_clases]\n",
        "\n",
        "# Guardar resultados en CSV\n",
        "resultado = pd.DataFrame({\n",
        "    \"ID\": df_test_final[\"ID\"],\n",
        "    \"RENDIMIENTO_GLOBAL\": y_pred_labels\n",
        "})\n",
        "\n",
        "resultado.to_csv(\"predicciones_test.csv\", index=False)\n",
        "print(\"Predicciones generadas\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcGo1JPDqSDI",
        "outputId": "57edbd4c-b9b4-419e-a939-899fc9f037a9"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicciones generadas\n"
          ]
        }
      ]
    }
  ]
}